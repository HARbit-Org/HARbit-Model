{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c2bac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# PERSONAL FUNCTIONS\n",
    "from plots import *\n",
    "from utils import *\n",
    "from functions.windows import create_feature_windows # creación de ventanas e ingenieria de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5103214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "df_accel = pl.read_csv(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\test\\data\\Watch_accelerometer.csv')\n",
    "df_gyro = pl.read_csv(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\test\\data\\Watch_gyroscope.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0266312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = normalize_columns(df_accel, user_col_name= \"User\", timestamp_col_name = \"Creation_Time\", \n",
    "                            label_col_name = \"gt\", x_col_name = 'x', y_col_name = 'y', z_col_name = 'z')\n",
    "df_gyro = normalize_columns(df_gyro, user_col_name= \"User\", timestamp_col_name = \"Creation_Time\", \n",
    "                            label_col_name = \"gt\", x_col_name = 'x', y_col_name = 'y', z_col_name = 'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67165279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sensors = df_gyro.join(df_accel, on = ['Subject-id', 'Timestamp', 'Activity Label'], how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91d23f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gyro_inner = df_all_sensors.select(\n",
    "    pl.col('Subject-id'),\n",
    "    pl.col('Activity Label'),\n",
    "    pl.col('Timestamp'),\n",
    "    pl.col('X').alias('X'),\n",
    "    pl.col('Y').alias('Y'),\n",
    "    pl.col('Z').alias('Z')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a87e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel_inner = df_all_sensors.select(\n",
    "    pl.col('Subject-id'),\n",
    "    pl.col('Activity Label'),\n",
    "    pl.col('Timestamp'),\n",
    "    pl.col('X_right').alias('X'),\n",
    "    pl.col('Y_right').alias('Y'),\n",
    "    pl.col('Z_right').alias('Z')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2b7a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = convert_timestamp(df_accel_inner)\n",
    "df_gyro = convert_timestamp(df_gyro_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "860d8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel_pro = create_feature_windows(df_accel, window_seconds = 5, overlap_percent = 50, sampling_rate = 100)\n",
    "df_gyro_pro = create_feature_windows(df_gyro, window_seconds = 5, overlap_percent = 50, sampling_rate = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b71751ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_combined = pd.merge(\n",
    "    df_gyro_pro,\n",
    "    df_accel_pro, \n",
    "    on=['Subject-id', 'Activity Label', 'window_start', 'window_end', 'sample_count'], \n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70f1e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\cnn-lstm_har_model_82.h5\")\n",
    "label_encoder = joblib.load(r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\config\\label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a1fe0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_combined = features_combined[features_combined['Activity Label'].isin(['walk', 'stairsup', 'sit', 'stand'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "66812968",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tempo = {'walk': 'A', 'stairsup' : 'C', 'sit': 'D', 'stand': 'E'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "265607e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_combined['Activity Label'] = label_encoder.transform(features_combined['Activity Label'].apply(lambda x: dict_tempo[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69820f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_for_cnn_lstm_direct(features_df):\n",
    "    \"\"\"\n",
    "    Prepara características ya extraídas DIRECTAMENTE para CNN-LSTM\n",
    "    Sin crear ventanas adicionales - cada fila es una muestra independiente\n",
    "    \"\"\"\n",
    "    # Convertir a pandas si es necesario\n",
    "    if hasattr(features_df, 'to_pandas'):\n",
    "        features_df = features_df.to_pandas()\n",
    "\n",
    "    # Identificar columnas de características\n",
    "    metadata_cols = ['Subject-id', 'Activity Label', 'window_start', 'window_end', 'sample_count']\n",
    "    feature_cols = [col for col in features_df.columns if col not in metadata_cols]\n",
    "    \n",
    "    print(f\"Características detectadas: {len(feature_cols)}\")\n",
    "    print(f\"Muestras totales: {len(features_df)}\")\n",
    "    \n",
    "    # Extraer características y etiquetas directamente\n",
    "    X = features_df[feature_cols].values\n",
    "    y = features_df['Activity Label'].values\n",
    "    subjects = features_df['Subject-id'].values\n",
    "    \n",
    "    # Reshape para CNN: (samples, timesteps=1, features)\n",
    "    # Cada ventana de 5s es una muestra individual\n",
    "    X_reshaped = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "    return X_reshaped, y, subjects #, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4ccf904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características detectadas: 136\n",
      "Muestras totales: 2923\n"
     ]
    }
   ],
   "source": [
    "x, y, _ = prepare_features_for_cnn_lstm_direct(features_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b469b180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "43506171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'C', 'D', 'E']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres_clases_filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d666d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando modelo...\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Pérdida en test: 9.4177\n",
      "Precisión en test: 0.1016\n",
      "\n",
      "==================================================\n",
      "REPORTE DE CLASIFICACIÓN\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 5, does not match size of target_names, 4. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPORTE DE CLASIFICACIÓN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnombres_clases_filtrados\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdigits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[0;32m     27\u001b[0m \u001b[43m)\u001b[49m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Matriz de confusión (usando las etiquetas filtradas)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y, y_pred_classes)\n",
      "File \u001b[1;32mc:\\Users\\HP\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\HP\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2648\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2642\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2643\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2644\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2645\u001b[0m             )\n\u001b[0;32m   2646\u001b[0m         )\n\u001b[0;32m   2647\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2648\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2649\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2650\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2651\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2652\u001b[0m         )\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2654\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 5, does not match size of target_names, 4. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Obtener las clases únicas presentes en tus datos de prueba\n",
    "clases_presentes = np.unique(y)\n",
    "\n",
    "# Obtener los nombres de las clases correspondientes del label_encoder\n",
    "nombres_clases_filtrados = [label_encoder.classes_[i] for i in clases_presentes]\n",
    "\n",
    "print(\"Evaluando modelo...\")\n",
    "\n",
    "# Predicciones\n",
    "y_pred = model.predict(x)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Métricas básicas\n",
    "test_loss, test_accuracy = model.evaluate(x, y, verbose=0)\n",
    "print(f\"\\nPérdida en test: {test_loss:.4f}\")\n",
    "print(f\"Precisión en test: {test_accuracy:.4f}\")\n",
    "\n",
    "# Reporte de clasificación detallado (usando las etiquetas filtradas)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REPORTE DE CLASIFICACIÓN\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(\n",
    "    y, \n",
    "    y_pred_classes, \n",
    "    target_names=nombres_clases_filtrados,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# Matriz de confusión (usando las etiquetas filtradas)\n",
    "cm = confusion_matrix(y, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=nombres_clases_filtrados,\n",
    "    yticklabels=nombres_clases_filtrados\n",
    ")\n",
    "plt.title('Matriz de Confusión - CNN-LSTM')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbd75ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_plot(pl.DataFrame(features_combined), 'balance_plot_uci_activities')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
