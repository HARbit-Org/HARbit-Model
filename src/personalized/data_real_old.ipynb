{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93be17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder, \n",
    "    StandardScaler,\n",
    "    label_binarize\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Save variables for model\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "# PERSONAL FUNCTIONS\n",
    "from utils import *\n",
    "from models.main import *\n",
    "from models.optimizer import ViterbiLiteDecoder\n",
    "from functions.windows import create_feature_windows # creación de ventanas e ingenieria de características\n",
    "from functions.build_window_raw import create_raw_windows_250_timesteps_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc87212",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_preds = {\n",
    "    'Eat': {'y': [], 'y_pred': []},\n",
    "    'Stand': {'y': [], 'y_pred': []},\n",
    "    'Walk': {'y': [], 'y_pred': []},\n",
    "    'Sit': {'y': [], 'y_pred': []},\n",
    "    'Type': {'y': [], 'y_pred': []}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16dd97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_result = {\n",
    "            'Eat': {'Accuracy' : [], 'F1-score': [], 'Precision': [], 'Recall': []}, \n",
    "            'Walk': {'Accuracy' : [], 'F1-score': [], 'Precision': [], 'Recall': []},\n",
    "            'Sit': {'Accuracy' : [], 'F1-score': [], 'Precision': [], 'Recall': []},\n",
    "            'Stand': {'Accuracy' : [], 'F1-score': [], 'Precision': [], 'Recall': []},\n",
    "            'Type': {'Accuracy' : [], 'F1-score': [], 'Precision': [], 'Recall': []}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23627b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\version\\sensors\\accel_cnn-lstm_wisdm_91_cluster_user.h5\")\n",
    "label_encoder = joblib.load(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\meta\\sensors\\accel_cnn-lstm_wisdm_91_cluster_user.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977f87ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Secuencias creadas: (7, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Eat']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644ms/step\n",
      "✅ Secuencias creadas: (24, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
      "✅ Secuencias creadas: (17, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "✅ Secuencias creadas: (17, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "✅ Secuencias creadas: (22, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "✅ Secuencias creadas: (16, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "✅ Secuencias creadas: (16, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "✅ Secuencias creadas: (24, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "✅ Secuencias creadas: (13, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "✅ Secuencias creadas: (15, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Sit']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "✅ Secuencias creadas: (21, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "✅ Secuencias creadas: (15, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "✅ Secuencias creadas: (15, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "✅ Secuencias creadas: (16, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "✅ Secuencias creadas: (16, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "✅ Secuencias creadas: (17, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "✅ Secuencias creadas: (17, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "✅ Secuencias creadas: (15, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "✅ Secuencias creadas: (17, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Stand']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "✅ Secuencias creadas: (20, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "✅ Secuencias creadas: (19, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "✅ Secuencias creadas: (16, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "✅ Secuencias creadas: (19, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "✅ Secuencias creadas: (18, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "✅ Secuencias creadas: (20, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "✅ Secuencias creadas: (18, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "✅ Secuencias creadas: (20, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "✅ Secuencias creadas: (20, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "✅ Secuencias creadas: (19, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "✅ Secuencias creadas: (18, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "✅ Secuencias creadas: (20, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "✅ Secuencias creadas: (56, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Walk']\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "✅ Secuencias creadas: (542, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Walk']\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "✅ Secuencias creadas: (3, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Walk']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "✅ Secuencias creadas: (331, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Walk']\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "path_base = r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\data\\real-data\"\n",
    "archive_date = [archive for archive in os.listdir(r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\data\\real-data\") if '.json' not in archive]\n",
    "\n",
    "\n",
    "for data in archive_date:\n",
    "    path_data = os.path.join(path_base, data)\n",
    "    file_data = os.listdir(path_data)\n",
    "\n",
    "    target = data.split('-')[0].title()\n",
    "    for file in file_data:\n",
    "\n",
    "        file_path = os.path.join(path_data, file)\n",
    "        \n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        accel_df = data['accel']\n",
    "\n",
    "        accel_temp = pl.DataFrame(accel_df)\n",
    "        \n",
    "        accel_temp = accel_temp.with_columns(pl.lit('A').alias('Usuario'))\n",
    "\n",
    "        accel_temp = accel_temp.with_columns(pl.lit(target).alias('gt'))\n",
    "\n",
    "        df_accel = normalize_columns(accel_temp,\n",
    "                            user_col_name  = \"Usuario\", \n",
    "                            timestamp_col_name = \"timestamp\", \n",
    "                            label_col_name = \"gt\", \n",
    "                            x_col_name = \"x\", \n",
    "                            y_col_name = \"y\", \n",
    "                            z_col_name = \"z\"\n",
    "                        )\n",
    "        \n",
    "        df_accel = convert_timestamp(df_accel)\n",
    "\n",
    "        features_accel = create_feature_windows(df_accel, window_seconds=5, overlap_percent=50)\n",
    "\n",
    "        X_all, y_all, _, le = prepare_features_for_cnn_lstm_sequences(\n",
    "            features_accel,\n",
    "            group_size = 8, \n",
    "            step_size = 1\n",
    "        )\n",
    "\n",
    "        y_all = le.inverse_transform(y_all)\n",
    "        y_all = label_encoder.transform(y_all)\n",
    "\n",
    "        num_classes = len(label_encoder.classes_)\n",
    "\n",
    "        # Predicciones\n",
    "        y_pred = model.predict(X_all)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Comparar con y_real (asegúrate de que y_real tenga etiquetas 0..N-1)\n",
    "        acc = accuracy_score(y_all, y_pred_classes)\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                y_all, y_pred_classes, average='macro', zero_division=0\n",
    "            )\n",
    "        \n",
    "        dic_result[target]['Accuracy'].append(acc*100)\n",
    "        dic_result[target]['F1-score'].append(f1*100)\n",
    "        dic_result[target]['Precision'].append(precision*100)\n",
    "        dic_result[target]['Recall'].append(recall*100)\n",
    "\n",
    "        dict_preds[target]['y'].extend(y_all)\n",
    "        dict_preds[target]['y_pred'].extend(y_pred_classes)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64849c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Eat       0.01      0.29      0.02         7\n",
      "         Sit       0.27      0.08      0.12       164\n",
      "       Stand       0.19      0.15      0.17       149\n",
      "        Type       0.00      0.00      0.00       227\n",
      "        Walk       0.80      0.58      0.68       932\n",
      "\n",
      "   micro avg       0.54      0.39      0.45      1479\n",
      "   macro avg       0.25      0.22      0.20      1479\n",
      "weighted avg       0.56      0.39      0.46      1479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true_global = []\n",
    "y_pred_global = []\n",
    "\n",
    "for activity in dict_preds.keys():\n",
    "    y_true_global.extend(dict_preds[activity]['y'])\n",
    "    y_pred_global.extend(dict_preds[activity]['y_pred'])\n",
    "\n",
    "labels = np.unique(y_true_global)  # clases presentes en los datos\n",
    "target_names = label_encoder.inverse_transform(labels)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true_global, y_pred_global,\n",
    "    labels=labels,\n",
    "    target_names=target_names\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
