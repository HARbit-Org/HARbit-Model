{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3d80f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder, \n",
    "    StandardScaler,\n",
    "    label_binarize\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Save variables for model\n",
    "import joblib\n",
    "\n",
    "# PERSONAL FUNCTIONS\n",
    "from utils import *\n",
    "from models.main import *\n",
    "from models.optimizer import ViterbiLiteDecoder\n",
    "from functions.windows import create_feature_windows # creaci√≥n de ventanas e ingenieria de caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultados = { 'Sit': [], 'Stand': [], 'Type': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564fa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0, 0.0),\n",
       " (0.11764705882352941, 0.0, -0.11764705882352941),\n",
       " (0.058823529411764705, 0.0, -0.058823529411764705),\n",
       " (0.0, 0.0, 0.0),\n",
       " (0.0, 0.0, 0.0),\n",
       " (0.0, 0.0, 0.0),\n",
       " (0.0, 0.0, 0.0),\n",
       " (0.0, 0.0, 0.0),\n",
       " (0.0, 0.0, 0.0)]"
      ]
     },
     "execution_count": 1236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados[target][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sit': [(0.08333333333333333, 0.0, -0.08333333333333333),\n",
       "  (0.058823529411764705, 0.0, -0.058823529411764705),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.25, 0.25, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.25, 0.2916666666666667, 0.041666666666666685),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0)],\n",
       " 'Stand': [(0.14285714285714285, 0.19047619047619047, 0.047619047619047616),\n",
       "  (0.06666666666666667, 0.0, -0.06666666666666667),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.125, 0.125, 0.0),\n",
       "  (0.058823529411764705, 0.0, -0.058823529411764705),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.5333333333333333, 0.5333333333333333, 0.0),\n",
       "  (0.11764705882352941, 0.0, -0.11764705882352941)],\n",
       " 'Type': [(0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.11764705882352941, 0.0, -0.11764705882352941),\n",
       "  (0.058823529411764705, 0.0, -0.058823529411764705),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0),\n",
       "  (0.0, 0.0, 0.0)]}"
      ]
     },
     "execution_count": 1499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "id": "447eabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = \"09\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "id": "1a2f7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\data\\real-data\\type-data\\type_left_04.json\"\n",
    "data = r\"type_left_04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "id": "5ddc8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(path, 'rb') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "gyro_df = data['gyro']\n",
    "accel_df = data['accel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1524,
   "id": "8d949116",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "id": "3e6157e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp = pl.DataFrame(accel_df)\n",
    "gyro_temp = pl.DataFrame(gyro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "id": "8b3ea5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp = accel_temp.with_columns(pl.lit('A').alias('Usuario'))\n",
    "gyro_temp  = gyro_temp.with_columns(pl.lit('A').alias('Usuario'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "id": "7fb43d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp   = accel_temp.with_columns(pl.lit(target).alias('gt'))\n",
    "gyro_temp    = gyro_temp.with_columns(pl.lit(target).alias('gt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1528,
   "id": "dce7a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = normalize_columns(accel_temp,\n",
    "                            user_col_name  = \"Usuario\", \n",
    "                            timestamp_col_name = \"timestamp\", \n",
    "                            label_col_name = \"gt\", \n",
    "                            x_col_name = \"x\", \n",
    "                            y_col_name = \"y\", \n",
    "                            z_col_name = \"z\")\n",
    "\n",
    "df_gyro = normalize_columns(gyro_temp, \n",
    "                            user_col_name  = \"Usuario\", \n",
    "                            timestamp_col_name = \"timestamp\", \n",
    "                            label_col_name = \"gt\", \n",
    "                            x_col_name = \"x\", \n",
    "                            y_col_name = \"y\", \n",
    "                            z_col_name = \"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "id": "64cea588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_sensors = df_gyro.join(df_accel, on = ['Subject-id', 'Timestamp', 'Activity Label'], how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "id": "cfcd2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gyro = df_all_sensors.select([\n",
    "#     'Subject-id',\n",
    "#     'Timestamp',\n",
    "#     'Activity Label',\n",
    "#     'X',\n",
    "#     'Y',\n",
    "#     'Z'\n",
    "# ])\n",
    "\n",
    "# df_accel = df_all_sensors.select([\n",
    "#     'Subject-id',\n",
    "#     'Timestamp',\n",
    "#     'Activity Label',\n",
    "#     pl.col('X_right').alias('X'),\n",
    "#     pl.col('Y_right').alias('Y'),\n",
    "#     pl.col('Z_right').alias('Z')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1531,
   "id": "26a5ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = convert_timestamp(df_accel)\n",
    "df_gyro = convert_timestamp(df_gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "id": "3447884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_sensors = df_gyro.join(df_accel, on = ['Subject-id', 'Timestamp', 'Activity Label'], how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1533,
   "id": "e5255e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gyro = df_all_sensors.select(\n",
    "#     pl.col('Subject-id'),\n",
    "#     pl.col('Timestamp'),\n",
    "#     pl.col('Activity Label'),\n",
    "#     pl.col('X'),\n",
    "#     pl.col('Y'),\n",
    "#     pl.col('Z')\n",
    "# )\n",
    "\n",
    "# df_accel = df_all_sensors.select(\n",
    "#     pl.col('Subject-id'),\n",
    "#     pl.col('Timestamp'),\n",
    "#     pl.col('Activity Label'),\n",
    "#     pl.col('X_right').alias('X'),\n",
    "#     pl.col('Y_right').alias('Y'),\n",
    "#     pl.col('Z_right').alias('Z')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "id": "1cf30484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_axes_by_activity(df_gyro, df_accel, max_samples_per_activity=1000, figsize=(15, 12)):\n",
    "    \"\"\"\n",
    "    Visualiza los ejes X, Y, Z del giroscopio y aceler√≥metro por cada actividad\n",
    "    \"\"\"\n",
    "    # Obtener actividades √∫nicas\n",
    "    activities = df_gyro['Activity Label'].unique().tolist()\n",
    "    n_activities = len(activities)\n",
    "    \n",
    "    # Crear subplots\n",
    "    fig, axes = plt.subplots(n_activities, 2, figsize=figsize)\n",
    "    if n_activities == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, activity in enumerate(activities):\n",
    "        # Filtrar datos por actividad\n",
    "        gyro_activity = df_gyro[df_gyro['Activity Label'] == activity]\n",
    "        accel_activity =  df_accel[df_accel['Activity Label'] == activity]\n",
    "        \n",
    "        # Limitar muestras para mejor visualizaci√≥n\n",
    "        if len(gyro_activity) > max_samples_per_activity:\n",
    "            gyro_activity = gyro_activity.head(max_samples_per_activity)\n",
    "        if len(accel_activity) > max_samples_per_activity:\n",
    "            accel_activity = accel_activity.head(max_samples_per_activity)\n",
    "        \n",
    "        # Convertir a pandas para plotting\n",
    "        gyro_pd = gyro_activity.copy()\n",
    "        accel_pd = accel_activity.copy()\n",
    "        \n",
    "        # Plot Giroscopio\n",
    "        axes[i, 0].plot(gyro_pd['X'], label='X', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].plot(gyro_pd['Y'], label='Y', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].plot(gyro_pd['Z'], label='Z', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].set_title(f'Giroscopio - {activity}')\n",
    "        axes[i, 0].set_ylabel('Valor')\n",
    "        axes[i, 0].legend()\n",
    "        axes[i, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot Aceler√≥metro\n",
    "        axes[i, 1].plot(accel_pd['X'], label='X', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].plot(accel_pd['Y'], label='Y', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].plot(accel_pd['Z'], label='Z', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].set_title(f'Aceler√≥metro - {activity}')\n",
    "        axes[i, 1].set_ylabel('Valor')\n",
    "        axes[i, 1].legend()\n",
    "        axes[i, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # A√±adir xlabel solo en la √∫ltima fila\n",
    "        if i == n_activities - 1:\n",
    "            axes[i, 0].set_xlabel('Muestra')\n",
    "            axes[i, 1].set_xlabel('Muestra')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar visualizaci√≥n\n",
    "# plot_axes_by_activity(df_gyro.to_pandas(), df_accel.to_pandas(), max_samples_per_activity = 2000,  figsize = (20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "id": "62ad9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_gyro   = create_feature_windows(df_gyro, window_seconds = 5, overlap_percent=50, sampling_rate = 20)\n",
    "features_accel  = create_feature_windows(df_accel, window_seconds = 5, overlap_percent=50, sampling_rate = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "id": "a90de002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dic = adaptive_transfer_learning_cnn_lstm(\n",
    "#     base_model_path = r'F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\version\\sensors\\accel_cnn-lstm_wisdm_91_cluster_user.h5', \n",
    "#     target_X = features_accel.drop(columns = ['Subject-id', 'Activity Label']),\n",
    "#     target_y = features_accel['Activity Label'],\n",
    "#     target_le = ,\n",
    "#     source_X = None,\n",
    "#     source_y = None, \n",
    "#     source_le = None,\n",
    "#     validation_split = 0.2,\n",
    "#     progressive_training = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1537,
   "id": "bab1d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_combined = pd.merge(\n",
    "#     features_gyro,\n",
    "#     features_accel, \n",
    "#     on=['Subject-id', 'Activity Label', 'window_start', 'window_end', 'sample_count'], \n",
    "#     how=\"inner\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "id": "051b0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "id": "1e753555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Secuencias creadas: (19, 8, 68)\n",
      "  Num features: 68\n",
      "  Clases: ['Type']\n",
      "Forma de X (secuencias): (19, 8, 68)\n",
      "Forma de y: (19,)\n",
      "Actividades √∫nicas: [0]\n"
     ]
    }
   ],
   "source": [
    "X, y, _, le = prepare_features_for_cnn_lstm_sequences(\n",
    "    features_accel, \n",
    "    group_size=8, \n",
    "    step_size=1\n",
    ")\n",
    "\n",
    "print(f\"Forma de X (secuencias): {X.shape}\")   # (N, group_size, features)\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "print(f\"Actividades √∫nicas: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "id": "5298b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "id": "d2086faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\version\\sensors\\accel_cnn-lstm_wisdm_91_cluster_user.h5')\n",
    "label_encoder = joblib.load(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\meta\\sensors\\accel_cnn-lstm_wisdm_91_cluster_user.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1542,
   "id": "7f0167f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "id": "9208b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando modelo...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779ms/step\n",
      "‚úÖ Accuracy filtrado (solo clases presentes en el dataset): 0.0000\n",
      "\n",
      "P√©rdida en test: 6.2503\n",
      "Precisi√≥n en test: 0.0000\n",
      "\n",
      "==================================================\n",
      "REPORTE DE CLASIFICACI√ìN\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Type     0.0000    0.0000    0.0000      19.0\n",
      "\n",
      "   micro avg     0.0000    0.0000    0.0000      19.0\n",
      "   macro avg     0.0000    0.0000    0.0000      19.0\n",
      "weighted avg     0.0000    0.0000    0.0000      19.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\miniconda3\\envs\\forecasting\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluando modelo...\")\n",
    "# Predicciones\n",
    "y_pred = model.predict(X)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Obtener las clases que realmente existen en este conjunto de datos\n",
    "unique_classes = np.unique(y)\n",
    "\n",
    "# Calcular accuracy SOLO en esas clases\n",
    "mask = np.isin(y, unique_classes)\n",
    "filtered_accuracy = accuracy_score(y[mask], y_pred_classes[mask])\n",
    "\n",
    "print(f\"‚úÖ Accuracy filtrado (solo clases presentes en el dataset): {filtered_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# M√©tricas b√°sicas\n",
    "test_loss, test_accuracy = model.evaluate(X, y, verbose=0)\n",
    "print(f\"\\nP√©rdida en test: {test_loss:.4f}\")\n",
    "print(f\"Precisi√≥n en test: {test_accuracy:.4f}\")\n",
    "\n",
    "# Reporte de clasificaci√≥n detallado\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REPORTE DE CLASIFICACI√ìN\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(\n",
    "    y, \n",
    "    y_pred_classes, \n",
    "    labels=unique_classes,               # solo las clases presentes\n",
    "    target_names=label_encoder.classes_[unique_classes],\n",
    "    digits=4\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "id": "f9d79fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fq = {label_encoder.classes_[yb]: 0 for yb in np.unique(y_pred_classes)}\n",
    "\n",
    "for lb in y_pred_classes:\n",
    "    fq[label_encoder.classes_[lb]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "id": "d4092eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Eat': 6, 'Others': 4, 'Sit': 1, 'Stand': 2, 'Walk': 6}"
      ]
     },
     "execution_count": 1545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "id": "62dfa856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.optimizer.ViterbiLiteDecoder import ViterbiLiteDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "id": "f424f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_viterbi_to_har_results(model, X_test, y_test, label_encoder, \n",
    "                                visualization=True, save_results=True):\n",
    "    \"\"\"\n",
    "    Aplica Viterbi-lite a resultados de HAR\n",
    "    \"\"\"\n",
    "    print(\"üöÄ APLICANDO VITERBI-LITE A RESULTADOS HAR\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Obtener probabilidades del modelo\n",
    "    print(\"üîç Extrayendo probabilidades...\")\n",
    "    probabilities = model.predict(X_test)\n",
    "    original_predictions = np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    # 2. Crear decodificador con clases espec√≠ficas\n",
    "    classes = label_encoder.classes_\n",
    "    decoder = ViterbiLiteDecoder(\n",
    "        classes=classes,\n",
    "        transition_penalty=2.5,  # Ajustar seg√∫n tus necesidades\n",
    "        self_bonus=1.8,\n",
    "        min_duration={\n",
    "            'Walk': 3,       # 15 segundos\n",
    "            'Sit': 4,        # 20 segundos  \n",
    "            'Stand': 2,      # 10 segundos\n",
    "            'Type': 6,       # 30 segundos\n",
    "            'Eat': 4,        # 20 segundos\n",
    "            'Write': 4,      # 20 segundos\n",
    "            'Workouts': 8,   # 40 segundos\n",
    "            'Others': 1      # Sin restricci√≥n\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 3. Decodificar secuencia\n",
    "    print(\"üß† Decodificando secuencia con Viterbi...\")\n",
    "    decoded_sequence, viterbi_scores = decoder.decode_complete_pipeline(\n",
    "        probabilities=probabilities,\n",
    "        apply_duration_constraints=True\n",
    "    )\n",
    "    \n",
    "    # 4. Evaluar mejoras\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    \n",
    "    original_accuracy = accuracy_score(y_test, original_predictions)\n",
    "    viterbi_accuracy = accuracy_score(y_test, decoded_sequence)\n",
    "    \n",
    "    print(f\"\\nüìä RESULTADOS:\")\n",
    "    print(f\"üîµ Accuracy original: {original_accuracy:.4f}\")\n",
    "    print(f\"üü¢ Accuracy con Viterbi: {viterbi_accuracy:.4f}\")\n",
    "    print(f\"üìà Mejora: {viterbi_accuracy - original_accuracy:.4f}\")\n",
    "    \n",
    "    # 5. An√°lisis de cambios\n",
    "    changes = np.sum(original_predictions != decoded_sequence)\n",
    "    print(f\"üîÑ Frames modificados: {changes}/{len(y_test)} ({100*changes/len(y_test):.1f}%)\")\n",
    "    \n",
    "    # 7. Visualizaci√≥n\n",
    "    # if visualization:\n",
    "    #     decoder.visualize_decoding(\n",
    "    #         original_sequence=original_predictions,\n",
    "    #         decoded_sequence=decoded_sequence,\n",
    "    #         probabilities=probabilities,\n",
    "    #         save_path='viterbi_analysis.png' if save_results else None\n",
    "    #     )\n",
    "    \n",
    "    # 8. Guardar resultados\n",
    "    # if save_results:\n",
    "    #     import joblib\n",
    "    #     results = {\n",
    "    #         'original_predictions': original_predictions,\n",
    "    #         'viterbi_predictions': decoded_sequence,\n",
    "    #         'probabilities': probabilities,\n",
    "    #         'viterbi_scores': viterbi_scores,\n",
    "    #         'accuracy_improvement': viterbi_accuracy - original_accuracy,\n",
    "    #         'decoder_config': {\n",
    "    #             'classes': classes.tolist(),\n",
    "    #             'transition_penalty': decoder.transition_penalty,\n",
    "    #             'self_bonus': decoder.self_bonus,\n",
    "    #             'min_duration': decoder.min_duration\n",
    "    #         }\n",
    "    #     }\n",
    "        \n",
    "    #     joblib.dump(results, 'viterbi_har_results.joblib')\n",
    "    #     print(\"üíæ Resultados guardados en 'viterbi_har_results.joblib'\")\n",
    "    \n",
    "    return {\n",
    "        'decoder': decoder,\n",
    "        'original_predictions': original_predictions,\n",
    "        'viterbi_predictions': decoded_sequence,\n",
    "        'original_accuracy': original_accuracy,\n",
    "        'viterbi_accuracy': viterbi_accuracy,\n",
    "        'improvement': viterbi_accuracy - original_accuracy\n",
    "    }\n",
    "\n",
    "# Ejemplo de uso con tu modelo\n",
    "def run_viterbi_on_trained_model():\n",
    "    \"\"\"\n",
    "    Ejecuta Viterbi en tu modelo ya entrenado\n",
    "    \"\"\"\n",
    "    # Cargar tu modelo y datos\n",
    "    from tensorflow import keras\n",
    "    import joblib\n",
    "    \n",
    "    model = keras.models.load_model(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\version\\sensors\\accel_cnn-lstm_wisdm_91_cluster_user.h5')\n",
    "    label_encoder = joblib.load(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\models\\meta\\sensors\\accel_cnn-lstm_wisdm_91_cluster_user.joblib')\n",
    "    \n",
    "    # X_test, y_test = cargar_tus_datos_de_test()\n",
    "    \n",
    "    # Aplicar Viterbi\n",
    "    results = apply_viterbi_to_har_results(\n",
    "        model=model,\n",
    "        X_test=X,\n",
    "        y_test=y,\n",
    "        label_encoder=label_encoder,\n",
    "        visualization=True,\n",
    "        save_results=True\n",
    "    )\n",
    "    \n",
    "    print(f\"üéâ Viterbi completado con mejora de {results['improvement']:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "id": "c277198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ APLICANDO VITERBI-LITE A RESULTADOS HAR\n",
      "============================================================\n",
      "üîç Extrayendo probabilidades...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
      "üß† Decodificando secuencia con Viterbi...\n",
      "üß† Decodificando con probabilidades (Viterbi completo)\n",
      "‚è±Ô∏è Aplicando restricciones de duraci√≥n m√≠nima\n",
      "\n",
      "üìä RESULTADOS:\n",
      "üîµ Accuracy original: 0.0000\n",
      "üü¢ Accuracy con Viterbi: 0.0000\n",
      "üìà Mejora: 0.0000\n",
      "üîÑ Frames modificados: 5/19 (26.3%)\n",
      "üéâ Viterbi completado con mejora de 0.0000\n"
     ]
    }
   ],
   "source": [
    "rs = run_viterbi_on_trained_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "id": "34865d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[target].append((rs['original_accuracy'], rs['viterbi_accuracy'], rs['improvement']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
