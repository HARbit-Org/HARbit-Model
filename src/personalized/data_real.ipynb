{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d80f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder, \n",
    "    StandardScaler,\n",
    "    label_binarize\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Save variables for model\n",
    "import joblib\n",
    "\n",
    "# PERSONAL FUNCTIONS\n",
    "from utils import *\n",
    "from models.main import *\n",
    "from models.optimizer import ViterbiLiteDecoder\n",
    "from functions.windows import create_feature_windows # creación de ventanas e ingenieria de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "d2c23463",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "ee490aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642857142857143"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "4276f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "e5708796",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\data\\real-data\\sit-data\\sit_left_0\" + str(id) + \".json\"\n",
    "id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "1a2f7c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\UPC\\\\Tesis\\\\HARbit-Model\\\\src\\\\data\\\\real-data\\\\sit-data\\\\sit_left_09.json'"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = temp\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "8d949116",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Sit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "5ddc8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(path, 'rb') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "gyro_df = data['gyro']\n",
    "accel_df = data['accel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "3e6157e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp = pl.DataFrame(accel_df)\n",
    "gyro_temp = pl.DataFrame(gyro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "8b3ea5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp = accel_temp.with_columns(pl.lit('A').alias('Usuario'))\n",
    "gyro_temp  = gyro_temp.with_columns(pl.lit('A').alias('Usuario'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "7fb43d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp   = accel_temp.with_columns(pl.lit(target).alias('gt'))\n",
    "gyro_temp    = gyro_temp.with_columns(pl.lit(target).alias('gt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "dce7a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = normalize_columns(accel_temp,\n",
    "                            user_col_name  = \"Usuario\", \n",
    "                            timestamp_col_name = \"timestamp\", \n",
    "                            label_col_name = \"gt\", \n",
    "                            x_col_name = \"x\", \n",
    "                            y_col_name = \"y\", \n",
    "                            z_col_name = \"z\")\n",
    "\n",
    "df_gyro = normalize_columns(gyro_temp, \n",
    "                            user_col_name  = \"Usuario\", \n",
    "                            timestamp_col_name = \"timestamp\", \n",
    "                            label_col_name = \"gt\", \n",
    "                            x_col_name = \"x\", \n",
    "                            y_col_name = \"y\", \n",
    "                            z_col_name = \"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "26a5ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = convert_timestamp(df_accel)\n",
    "df_gyro = convert_timestamp(df_gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "1cf30484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_axes_by_activity(df_gyro, df_accel, max_samples_per_activity=1000, figsize=(15, 12)):\n",
    "    \"\"\"\n",
    "    Visualiza los ejes X, Y, Z del giroscopio y acelerómetro por cada actividad\n",
    "    \"\"\"\n",
    "    # Obtener actividades únicas\n",
    "    activities = df_gyro['Activity Label'].unique().tolist()\n",
    "    n_activities = len(activities)\n",
    "    \n",
    "    # Crear subplots\n",
    "    fig, axes = plt.subplots(n_activities, 2, figsize=figsize)\n",
    "    if n_activities == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, activity in enumerate(activities):\n",
    "        # Filtrar datos por actividad\n",
    "        gyro_activity = df_gyro[df_gyro['Activity Label'] == activity]\n",
    "        accel_activity =  df_accel[df_accel['Activity Label'] == activity]\n",
    "        \n",
    "        # Limitar muestras para mejor visualización\n",
    "        if len(gyro_activity) > max_samples_per_activity:\n",
    "            gyro_activity = gyro_activity.head(max_samples_per_activity)\n",
    "        if len(accel_activity) > max_samples_per_activity:\n",
    "            accel_activity = accel_activity.head(max_samples_per_activity)\n",
    "        \n",
    "        # Convertir a pandas para plotting\n",
    "        gyro_pd = gyro_activity.copy()\n",
    "        accel_pd = accel_activity.copy()\n",
    "        \n",
    "        # Plot Giroscopio\n",
    "        axes[i, 0].plot(gyro_pd['X'], label='X', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].plot(gyro_pd['Y'], label='Y', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].plot(gyro_pd['Z'], label='Z', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].set_title(f'Giroscopio - {activity}')\n",
    "        axes[i, 0].set_ylabel('Valor')\n",
    "        axes[i, 0].legend()\n",
    "        axes[i, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot Acelerómetro\n",
    "        axes[i, 1].plot(accel_pd['X'], label='X', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].plot(accel_pd['Y'], label='Y', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].plot(accel_pd['Z'], label='Z', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].set_title(f'Acelerómetro - {activity}')\n",
    "        axes[i, 1].set_ylabel('Valor')\n",
    "        axes[i, 1].legend()\n",
    "        axes[i, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Añadir xlabel solo en la última fila\n",
    "        if i == n_activities - 1:\n",
    "            axes[i, 0].set_xlabel('Muestra')\n",
    "            axes[i, 1].set_xlabel('Muestra')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar visualización\n",
    "# plot_axes_by_activity(df_gyro.to_pandas(), df_accel.to_pandas(), max_samples_per_activity = 2000,  figsize = (20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "532d17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sampling_rate(df, user_id=None, activity=None, plot=True):\n",
    "    \"\"\"\n",
    "    Analiza la frecuencia de muestreo real de los datos\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con datos de sensores\n",
    "        user_id: Usuario específico (opcional)\n",
    "        activity: Actividad específica (opcional)\n",
    "        plot: Si mostrar gráficos\n",
    "    \n",
    "    Returns:\n",
    "        dict: Información detallada del muestreo\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Convertir a pandas si es necesario\n",
    "    if hasattr(df, 'to_pandas'):\n",
    "        df_pd = df.to_pandas()\n",
    "    else:\n",
    "        df_pd = df.copy()\n",
    "    \n",
    "    # Filtrar por usuario y/o actividad si se especifica\n",
    "    if user_id is not None:\n",
    "        df_pd = df_pd[df_pd['Subject-id'] == user_id]\n",
    "    if activity is not None:\n",
    "        df_pd = df_pd[df_pd['Activity Label'] == activity]\n",
    "    \n",
    "    # Asegurar que Timestamp es datetime\n",
    "    if df_pd['Timestamp'].dtype == 'object':\n",
    "        df_pd['Timestamp'] = pd.to_datetime(df_pd['Timestamp'])\n",
    "    elif df_pd['Timestamp'].dtype == 'int64':\n",
    "        df_pd['Timestamp'] = pd.to_datetime(df_pd['Timestamp'])\n",
    "    \n",
    "    print(f\"📊 ANÁLISIS DE FRECUENCIA DE MUESTREO\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"  Total de muestras: {len(df_pd):,}\")\n",
    "    \n",
    "    if len(df_pd) < 2:\n",
    "        print(\"❌ Insuficientes datos para análisis\")\n",
    "        return None\n",
    "    \n",
    "    # Ordenar por timestamp\n",
    "    df_pd = df_pd.sort_values('Timestamp')\n",
    "    \n",
    "    # Calcular diferencias de tiempo\n",
    "    time_diffs = df_pd['Timestamp'].diff().dt.total_seconds().dropna()\n",
    "    \n",
    "    # Estadísticas generales\n",
    "    total_duration = (df_pd['Timestamp'].max() - df_pd['Timestamp'].min()).total_seconds()\n",
    "    avg_sampling_rate = (len(df_pd) - 1) / total_duration if total_duration > 0 else 0\n",
    "    \n",
    "    print(f\"  Duración total: {total_duration:.2f} segundos\")\n",
    "    print(f\"  📡 Frecuencia promedio: {avg_sampling_rate:.2f} Hz\")\n",
    "    \n",
    "    # Estadísticas de intervalos\n",
    "    print(f\"\\n📈 ESTADÍSTICAS DE INTERVALOS:\")\n",
    "    print(f\"  Intervalo promedio: {time_diffs.mean():.4f}s ({1/time_diffs.mean():.1f} Hz)\")\n",
    "    print(f\"  Intervalo mínimo: {time_diffs.min():.4f}s ({1/time_diffs.min():.1f} Hz)\")\n",
    "    print(f\"  Intervalo máximo: {time_diffs.max():.4f}s ({1/time_diffs.max():.1f} Hz)\")\n",
    "    print(f\"  Desviación estándar: {time_diffs.std():.4f}s\")\n",
    "    \n",
    "    # Detectar frecuencias instantáneas\n",
    "    instant_frequencies = 1 / time_diffs\n",
    "    instant_frequencies = instant_frequencies[instant_frequencies < 1000]  # Filtrar valores extremos\n",
    "    \n",
    "    print(f\"\\n🎯 FRECUENCIAS INSTANTÁNEAS:\")\n",
    "    print(f\"  Frecuencia modal: {instant_frequencies.mode().iloc[0]:.1f} Hz\")\n",
    "    print(f\"  Mediana: {instant_frequencies.median():.1f} Hz\")\n",
    "    print(f\"  Rango: {instant_frequencies.min():.1f} - {instant_frequencies.max():.1f} Hz\")\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Análisis de Frecuencia de Muestreo', fontsize=16)\n",
    "        \n",
    "        # 1. Histograma de intervalos\n",
    "        axes[0,0].hist(time_diffs, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0,0].set_title('Distribución de Intervalos de Tiempo')\n",
    "        axes[0,0].set_xlabel('Intervalo (segundos)')\n",
    "        axes[0,0].set_ylabel('Frecuencia')\n",
    "        axes[0,0].axvline(time_diffs.mean(), color='red', linestyle='--', \n",
    "                         label=f'Media: {time_diffs.mean():.4f}s')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Histograma de frecuencias instantáneas\n",
    "        axes[0,1].hist(instant_frequencies, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[0,1].set_title('Distribución de Frecuencias Instantáneas')\n",
    "        axes[0,1].set_xlabel('Frecuencia (Hz)')\n",
    "        axes[0,1].set_ylabel('Frecuencia')\n",
    "        axes[0,1].axvline(instant_frequencies.median(), color='red', linestyle='--', \n",
    "                         label=f'Mediana: {instant_frequencies.median():.1f}Hz')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Serie temporal de intervalos\n",
    "        sample_indices = np.linspace(0, len(time_diffs)-1, min(1000, len(time_diffs))).astype(int)\n",
    "        axes[1,0].plot(sample_indices, time_diffs.iloc[sample_indices], 'b-', alpha=0.7, linewidth=1)\n",
    "        axes[1,0].set_title('Serie Temporal de Intervalos')\n",
    "        axes[1,0].set_xlabel('Muestra')\n",
    "        axes[1,0].set_ylabel('Intervalo (segundos)')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Serie temporal de frecuencias\n",
    "        axes[1,1].plot(sample_indices, instant_frequencies.iloc[sample_indices], 'g-', alpha=0.7, linewidth=1)\n",
    "        axes[1,1].set_title('Serie Temporal de Frecuencias')\n",
    "        axes[1,1].set_xlabel('Muestra')\n",
    "        axes[1,1].set_ylabel('Frecuencia (Hz)')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Detectar irregularidades\n",
    "    print(f\"\\n🔍 DETECCIÓN DE IRREGULARIDADES:\")\n",
    "    \n",
    "    # Gaps grandes (> 1 segundo)\n",
    "    large_gaps = time_diffs[time_diffs > 1.0]\n",
    "    print(f\"  Gaps > 1s: {len(large_gaps)} ({100*len(large_gaps)/len(time_diffs):.1f}%)\")\n",
    "    \n",
    "    # Variabilidad alta\n",
    "    cv = time_diffs.std() / time_diffs.mean()  # Coeficiente de variación\n",
    "    print(f\"  Coeficiente de variación: {cv:.3f}\")\n",
    "    \n",
    "    if cv > 0.1:\n",
    "        print(\"  ⚠️ Alta variabilidad en el muestreo\")\n",
    "    else:\n",
    "        print(\"  ✅ Muestreo relativamente estable\")\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df_pd),\n",
    "        'duration_seconds': total_duration,\n",
    "        'avg_sampling_rate': avg_sampling_rate,\n",
    "        'time_intervals': {\n",
    "            'mean': time_diffs.mean(),\n",
    "            'std': time_diffs.std(),\n",
    "            'min': time_diffs.min(),\n",
    "            'max': time_diffs.max()\n",
    "        },\n",
    "        'frequencies': {\n",
    "            'mean': instant_frequencies.mean(),\n",
    "            'median': instant_frequencies.median(),\n",
    "            'mode': instant_frequencies.mode().iloc[0] if len(instant_frequencies.mode()) > 0 else None,\n",
    "            'min': instant_frequencies.min(),\n",
    "            'max': instant_frequencies.max()\n",
    "        },\n",
    "        'irregularities': {\n",
    "            'large_gaps_count': len(large_gaps),\n",
    "            'coefficient_of_variation': cv\n",
    "        }\n",
    "    }\n",
    "\n",
    "# # Analizar tus datos\n",
    "# print(\"🔍 Analizando frecuencia de muestreo de df_accel...\")\n",
    "# sampling_info = analyze_sampling_rate(df_accel, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "34865d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_windows_250_timesteps_robust(df, window_seconds=5, overlap_percent=50, \n",
    "                                           sampling_rate=20, target_timesteps=250,\n",
    "                                           min_data_threshold=0.5, max_gap_seconds=1.0):\n",
    "    \"\"\"\n",
    "    Versión ROBUSTA: Crea ventanas basadas en TIEMPO REAL con validación mejorada\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con datos de sensores (Polars o Pandas)\n",
    "        window_seconds: Duración de la ventana en segundos (default: 5)\n",
    "        overlap_percent: Porcentaje de solapamiento (default: 50)\n",
    "        sampling_rate: Frecuencia de muestreo en Hz (default: 20)\n",
    "        target_timesteps: Número objetivo de timesteps por ventana (default: 250)\n",
    "        min_data_threshold: Umbral mínimo de datos válidos (0.5 = 50%)\n",
    "        max_gap_seconds: Máximo gap permitido en segundos (1.0s)\n",
    "        \n",
    "    Returns:\n",
    "        X: Array con forma (n_windows, 250, 3) - datos de ventanas\n",
    "        y: Array con etiquetas de actividad\n",
    "        subjects: Array con IDs de usuario\n",
    "        metadata: DataFrame con información de las ventanas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"🔧 Configuración de ventanas RAW ROBUSTA:\")\n",
    "    print(f\"  Duración: {window_seconds}s\")\n",
    "    print(f\"  Timesteps objetivo: {target_timesteps}\")\n",
    "    print(f\"  Frecuencia de muestreo: {sampling_rate}Hz\")\n",
    "    print(f\"  Solapamiento: {overlap_percent}%\")\n",
    "    print(f\"  Umbral mínimo de datos: {min_data_threshold*100:.1f}%\")\n",
    "    print(f\"  Máximo gap permitido: {max_gap_seconds}s\")\n",
    "    \n",
    "    # Convertir a pandas si es necesario\n",
    "    if hasattr(df, 'to_pandas'):\n",
    "        df_pd = df.to_pandas()\n",
    "    else:\n",
    "        df_pd = df.copy()\n",
    "    \n",
    "    # Asegurar que Timestamp es datetime\n",
    "    if df_pd['Timestamp'].dtype == 'object':\n",
    "        df_pd['Timestamp'] = pd.to_datetime(df_pd['Timestamp'])\n",
    "    elif df_pd['Timestamp'].dtype == 'int64':\n",
    "        df_pd['Timestamp'] = pd.to_datetime(df_pd['Timestamp'])\n",
    "    \n",
    "    # Calcular parámetros de tiempo\n",
    "    window_duration_ns = int(window_seconds * 1e9)\n",
    "    step_duration_ns = int(window_duration_ns * (100 - overlap_percent) / 100)\n",
    "    \n",
    "    print(f\"  Duración de ventana: {window_seconds}s\")\n",
    "    print(f\"  Paso entre ventanas: {step_duration_ns / 1e9:.2f}s\")\n",
    "    \n",
    "    # Listas para almacenar resultados\n",
    "    X_windows = []\n",
    "    y_labels = []\n",
    "    subjects_list = []\n",
    "    metadata_list = []\n",
    "    \n",
    "    total_windows_attempted = 0\n",
    "    total_windows_created = 0\n",
    "    \n",
    "    # Procesar por usuario y actividad\n",
    "    for (user_id, activity), group in df_pd.groupby(['Subject-id', 'Activity Label']):\n",
    "        \n",
    "        # Ordenar por timestamp y limpiar datos\n",
    "        group = group.sort_values('Timestamp').reset_index(drop=True)\n",
    "        group = group.dropna(subset=['X', 'Y', 'Z', 'Timestamp'])\n",
    "        \n",
    "        if len(group) < window_seconds * sampling_rate:\n",
    "            print(f\"⚠️ Usuario {user_id}, Actividad {activity}: Muy pocos datos ({len(group)} muestras)\")\n",
    "            continue\n",
    "        \n",
    "        # Convertir timestamps a nanosegundos\n",
    "        if group['Timestamp'].dtype.name.startswith('datetime'):\n",
    "            timestamps_ns = group['Timestamp'].astype('int64')\n",
    "        else:\n",
    "            timestamps_ns = group['Timestamp'].values\n",
    "        \n",
    "        print(f\"👤 Usuario {user_id}, Actividad {activity}: {len(group)} muestras\")\n",
    "        \n",
    "        # Obtener rango temporal\n",
    "        start_time_ns = timestamps_ns.min()\n",
    "        end_time_ns = timestamps_ns.max()\n",
    "        total_duration_s = (end_time_ns - start_time_ns) / 1e9\n",
    "        \n",
    "        print(f\"   Duración total: {total_duration_s:.1f}s\")\n",
    "        \n",
    "        # Detectar y reportar gaps grandes\n",
    "        time_diffs = np.diff(timestamps_ns) / 1e9  # Convertir a segundos\n",
    "        large_gaps = time_diffs > max_gap_seconds\n",
    "        if np.any(large_gaps):\n",
    "            n_gaps = np.sum(large_gaps)\n",
    "            max_gap = np.max(time_diffs)\n",
    "            print(f\"   ⚠️ Detectados {n_gaps} gaps > {max_gap_seconds}s (máximo: {max_gap:.1f}s)\")\n",
    "        \n",
    "        # Crear ventanas deslizantes\n",
    "        window_count = 0\n",
    "        current_start_ns = start_time_ns\n",
    "        \n",
    "        while current_start_ns + window_duration_ns <= end_time_ns:\n",
    "            total_windows_attempted += 1\n",
    "            current_end_ns = current_start_ns + window_duration_ns\n",
    "            \n",
    "            # Filtrar datos en esta ventana temporal\n",
    "            window_mask = (\n",
    "                (timestamps_ns >= current_start_ns) & \n",
    "                (timestamps_ns < current_end_ns)\n",
    "            )\n",
    "            window_data_df = group[window_mask]\n",
    "            \n",
    "            # Validación de ventana\n",
    "            is_valid, validation_info = validate_window_data(\n",
    "                window_data_df, \n",
    "                window_seconds, \n",
    "                sampling_rate, \n",
    "                min_data_threshold,\n",
    "                max_gap_seconds\n",
    "            )\n",
    "            \n",
    "            if is_valid:\n",
    "                # Extraer datos de sensores\n",
    "                sensor_data = window_data_df[['X', 'Y', 'Z']].values\n",
    "                window_timestamps = window_data_df['Timestamp'].values\n",
    "                \n",
    "                try:\n",
    "                    # Redimensionar/interpolar a target_timesteps\n",
    "                    resampled_window = resample_window_robust(\n",
    "                        sensor_data, window_timestamps, target_timesteps, window_seconds\n",
    "                    )\n",
    "                    \n",
    "                    # Verificar calidad final\n",
    "                    if is_window_quality_good(resampled_window):\n",
    "                        # Guardar datos\n",
    "                        X_windows.append(resampled_window)\n",
    "                        y_labels.append(activity)\n",
    "                        subjects_list.append(user_id)\n",
    "                        \n",
    "                        # Metadata extendida\n",
    "                        metadata_list.append({\n",
    "                            'Subject-id': user_id,\n",
    "                            'Activity Label': activity,\n",
    "                            'window_start': pd.to_datetime(current_start_ns),\n",
    "                            'window_end': pd.to_datetime(current_end_ns),\n",
    "                            'original_samples': len(window_data_df),\n",
    "                            'resampled_timesteps': target_timesteps,\n",
    "                            'window_idx': window_count,\n",
    "                            'actual_duration_s': window_seconds,\n",
    "                            'data_coverage': validation_info['data_coverage'],\n",
    "                            'max_gap_s': validation_info['max_gap'],\n",
    "                            'sampling_rate_actual': validation_info['actual_rate']\n",
    "                        })\n",
    "                        \n",
    "                        window_count += 1\n",
    "                        total_windows_created += 1\n",
    "                    else:\n",
    "                        print(f\"   ❌ Ventana {window_count}: Calidad de datos insuficiente después de interpolación\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Ventana {window_count}: Error en interpolación - {str(e)}\")\n",
    "            \n",
    "            else:\n",
    "                # No mostrar warning para cada ventana inválida, solo resumen\n",
    "                pass\n",
    "            \n",
    "            # Mover al siguiente inicio de ventana\n",
    "            current_start_ns += step_duration_ns\n",
    "        \n",
    "        print(f\"  ✅ Creadas {window_count} ventanas válidas\")\n",
    "    \n",
    "    # Resumen final\n",
    "    print(f\"\\n📊 RESUMEN DE VALIDACIÓN:\")\n",
    "    print(f\"  Ventanas intentadas: {total_windows_attempted}\")\n",
    "    print(f\"  Ventanas creadas: {total_windows_created}\")\n",
    "    print(f\"  Tasa de éxito: {(total_windows_created/total_windows_attempted)*100:.1f}%\")\n",
    "    \n",
    "    # Convertir a arrays numpy\n",
    "    if len(X_windows) > 0:\n",
    "        X = np.array(X_windows)\n",
    "        y = np.array(y_labels)\n",
    "        subjects = np.array(subjects_list)\n",
    "        metadata_df = pd.DataFrame(metadata_list)\n",
    "        \n",
    "        print(f\"\\n📊 RESULTADO FINAL (ROBUSTO):\")\n",
    "        print(f\"  Forma de X: {X.shape}\")\n",
    "        print(f\"  Forma de y: {y.shape}\")\n",
    "        print(f\"  Total ventanas: {len(X)}\")\n",
    "        print(f\"  Usuarios únicos: {len(np.unique(subjects))}\")\n",
    "        print(f\"  Actividades únicas: {sorted(np.unique(y))}\")\n",
    "        \n",
    "        return X, y, subjects, metadata_df\n",
    "    \n",
    "    else:\n",
    "        print(\"❌ No se crearon ventanas válidas\")\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "def validate_window_data(window_data_df, window_seconds, sampling_rate, \n",
    "                        min_data_threshold, max_gap_seconds):\n",
    "    \"\"\"\n",
    "    Valida si una ventana de datos es aceptable\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si la ventana es válida\n",
    "        dict: Información de validación\n",
    "    \"\"\"\n",
    "    if len(window_data_df) == 0:\n",
    "        return False, {'reason': 'empty', 'data_coverage': 0, 'max_gap': float('inf'), 'actual_rate': 0}\n",
    "    \n",
    "    # Calcular cobertura de datos esperada\n",
    "    expected_samples = window_seconds * sampling_rate\n",
    "    actual_samples = len(window_data_df)\n",
    "    data_coverage = actual_samples / expected_samples\n",
    "    \n",
    "    # Si hay muy pocos datos\n",
    "    if data_coverage < min_data_threshold:\n",
    "        return False, {\n",
    "            'reason': 'insufficient_data', \n",
    "            'data_coverage': data_coverage,\n",
    "            'max_gap': float('inf'),\n",
    "            'actual_rate': 0\n",
    "        }\n",
    "    \n",
    "    # Calcular gaps en los datos\n",
    "    if len(window_data_df) > 1:\n",
    "        timestamps = pd.to_datetime(window_data_df['Timestamp'])\n",
    "        time_diffs = timestamps.diff().dt.total_seconds().fillna(0)\n",
    "        max_gap = time_diffs.max()\n",
    "        actual_rate = len(window_data_df) / (timestamps.max() - timestamps.min()).total_seconds()\n",
    "    else:\n",
    "        max_gap = 0\n",
    "        actual_rate = sampling_rate\n",
    "    \n",
    "    # Si hay gaps muy grandes\n",
    "    if max_gap > max_gap_seconds:\n",
    "        return False, {\n",
    "            'reason': 'large_gap', \n",
    "            'data_coverage': data_coverage,\n",
    "            'max_gap': max_gap,\n",
    "            'actual_rate': actual_rate\n",
    "        }\n",
    "    \n",
    "    # Verificar que no hay valores NaN o infinitos en los sensores\n",
    "    sensor_data = window_data_df[['X', 'Y', 'Z']].values\n",
    "    if np.any(np.isnan(sensor_data)) or np.any(np.isinf(sensor_data)):\n",
    "        return False, {\n",
    "            'reason': 'invalid_values',\n",
    "            'data_coverage': data_coverage,\n",
    "            'max_gap': max_gap,\n",
    "            'actual_rate': actual_rate\n",
    "        }\n",
    "    \n",
    "    return True, {\n",
    "        'reason': 'valid',\n",
    "        'data_coverage': data_coverage,\n",
    "        'max_gap': max_gap,\n",
    "        'actual_rate': actual_rate\n",
    "    }\n",
    "\n",
    "\n",
    "def resample_window_robust(sensor_data, timestamps, target_timesteps, window_seconds):\n",
    "    \"\"\"\n",
    "    Versión robusta de remuestreo con múltiples estrategias\n",
    "    \"\"\"\n",
    "    from scipy.interpolate import interp1d\n",
    "    from scipy import signal\n",
    "    \n",
    "    if len(sensor_data) == 0:\n",
    "        return np.zeros((target_timesteps, 3))\n",
    "    \n",
    "    original_timesteps = len(sensor_data)\n",
    "    \n",
    "    if original_timesteps == target_timesteps:\n",
    "        return sensor_data.copy()\n",
    "    \n",
    "    if original_timesteps == 1:\n",
    "        return np.tile(sensor_data[0], (target_timesteps, 1))\n",
    "    \n",
    "    try:\n",
    "        # Estrategia 1: Interpolación temporal precisa\n",
    "        if hasattr(timestamps[0], 'timestamp'):\n",
    "            time_seconds = np.array([t.timestamp() for t in timestamps])\n",
    "        elif isinstance(timestamps[0], pd.Timestamp):\n",
    "            time_seconds = np.array([t.timestamp() for t in timestamps])\n",
    "        else:\n",
    "            time_seconds = timestamps.astype('int64') / 1e9\n",
    "        \n",
    "        # Normalizar tiempos\n",
    "        time_min = time_seconds.min()\n",
    "        time_max = time_seconds.max()\n",
    "        \n",
    "        if time_max > time_min:\n",
    "            relative_times = (time_seconds - time_min) / (time_max - time_min)\n",
    "        else:\n",
    "            relative_times = np.linspace(0, 1, len(time_seconds))\n",
    "        \n",
    "        # Crear tiempos objetivo uniformes\n",
    "        target_times = np.linspace(0, 1, target_timesteps)\n",
    "        \n",
    "        # Interpolar cada eje\n",
    "        resampled_data = np.zeros((target_timesteps, 3))\n",
    "        \n",
    "        for axis in range(3):\n",
    "            try:\n",
    "                # Estrategia de interpolación según la cantidad de datos\n",
    "                if original_timesteps >= target_timesteps:\n",
    "                    # Downsample: usar signal.resample para preservar características\n",
    "                    resampled_axis = signal.resample(sensor_data[:, axis], target_timesteps)\n",
    "                else:\n",
    "                    # Upsample: usar interpolación\n",
    "                    if len(np.unique(relative_times)) > 1:\n",
    "                        interpolator = interp1d(\n",
    "                            relative_times, \n",
    "                            sensor_data[:, axis],\n",
    "                            kind='cubic' if original_timesteps >= 4 else 'linear',\n",
    "                            bounds_error=False,\n",
    "                            fill_value='extrapolate'\n",
    "                        )\n",
    "                        resampled_axis = interpolator(target_times)\n",
    "                    else:\n",
    "                        resampled_axis = np.full(target_timesteps, sensor_data[0, axis])\n",
    "                \n",
    "                resampled_data[:, axis] = resampled_axis\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Fallback: interpolación lineal simple\n",
    "                resampled_data[:, axis] = np.interp(\n",
    "                    target_times, relative_times, sensor_data[:, axis]\n",
    "                )\n",
    "        \n",
    "        return resampled_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en remuestreo robusto: {str(e)}\")\n",
    "        # Último fallback: replicar la primera muestra\n",
    "        return np.tile(sensor_data[0], (target_timesteps, 1))\n",
    "\n",
    "\n",
    "def is_window_quality_good(resampled_window, max_std_threshold=50.0):\n",
    "    \"\"\"\n",
    "    Verifica la calidad final de una ventana remuestreada\n",
    "    \"\"\"\n",
    "    # Verificar NaN o infinitos\n",
    "    if np.any(np.isnan(resampled_window)) or np.any(np.isinf(resampled_window)):\n",
    "        return False\n",
    "    \n",
    "    # Verificar valores extremos (posibles errores de interpolación)\n",
    "    if np.any(np.abs(resampled_window) > 1000):  # Ajustar según tus datos\n",
    "        return False\n",
    "    \n",
    "    # Verificar varianza (datos demasiado planos pueden indicar error)\n",
    "    for axis in range(resampled_window.shape[1]):\n",
    "        std_axis = np.std(resampled_window[:, axis])\n",
    "        if std_axis > max_std_threshold:  # Varianza excesiva\n",
    "            return False\n",
    "        if std_axis < 0.001:  # Datos demasiado planos\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "97c88ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Configuración de ventanas RAW ROBUSTA:\n",
      "  Duración: 5s\n",
      "  Timesteps objetivo: 100\n",
      "  Frecuencia de muestreo: 20Hz\n",
      "  Solapamiento: 50%\n",
      "  Umbral mínimo de datos: 80.0%\n",
      "  Máximo gap permitido: 1.0s\n",
      "  Duración de ventana: 5s\n",
      "  Paso entre ventanas: 2.50s\n",
      "👤 Usuario A, Actividad Sit: 1459 muestras\n",
      "   Duración total: 58.0s\n",
      "  ✅ Creadas 22 ventanas válidas\n",
      "\n",
      "📊 RESUMEN DE VALIDACIÓN:\n",
      "  Ventanas intentadas: 22\n",
      "  Ventanas creadas: 22\n",
      "  Tasa de éxito: 100.0%\n",
      "\n",
      "📊 RESULTADO FINAL (ROBUSTO):\n",
      "  Forma de X: (22, 100, 3)\n",
      "  Forma de y: (22,)\n",
      "  Total ventanas: 22\n",
      "  Usuarios únicos: 1\n",
      "  Actividades únicas: ['Sit']\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all, subjects_all, metadata_all = create_raw_windows_250_timesteps_robust(\n",
    "    df=df_accel,\n",
    "    window_seconds=5,\n",
    "    overlap_percent=50,\n",
    "    sampling_rate=20,\n",
    "    target_timesteps=100,\n",
    "    min_data_threshold=0.8,  # 80% mínimo de datos\n",
    "    max_gap_seconds=1.0      # Máximo 1 segundo de gap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "c071f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "# Cargar como función concreta\n",
    "loaded = tf.saved_model.load(r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\cnn_temporal_20_epochs_93\\saved_model\")\n",
    "infer = loaded.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "e0328313",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.constant(X_all, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "5968a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = joblib.load(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\cnn_temporal_20_epochs_93\\label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "5fd61316",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = infer(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "a8b861c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = label_encoder.transform(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "308c6c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "[[22]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Ejemplo: y_pred con probabilidades\n",
    "y_pred_probs = list(y_pred.values())[0].numpy()\n",
    "\n",
    "# Convertir a clases predichas (índice del máximo)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Comparar con y_real (asegúrate de que y_real tenga etiquetas 0..N-1)\n",
    "acc = accuracy_score(y_all, y_pred_classes)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# Reporte más detallado\n",
    "print(classification_report(y_all, y_pred_classes))\n",
    "\n",
    "# Matriz de confusión\n",
    "print(confusion_matrix(y_all, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "dcbf119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "ba1790ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Eat', 'Others', 'Sit', 'Stand', 'Type', 'Walk', 'Workouts',\n",
       "       'Write'], dtype='<U8')"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "9e6e6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
