{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d80f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder, \n",
    "    StandardScaler,\n",
    "    label_binarize\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Save variables for model\n",
    "import joblib\n",
    "\n",
    "# PERSONAL FUNCTIONS\n",
    "from utils import *\n",
    "from models.main import *\n",
    "from models.optimizer import ViterbiLiteDecoder\n",
    "from functions.windows import create_feature_windows # creaci√≥n de ventanas e ingenieria de caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "d2c23463",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "ee490aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642857142857143"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "4276f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "e5708796",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\data\\real-data\\sit-data\\sit_left_0\" + str(id) + \".json\"\n",
    "id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "1a2f7c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\UPC\\\\Tesis\\\\HARbit-Model\\\\src\\\\data\\\\real-data\\\\sit-data\\\\sit_left_09.json'"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = temp\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "8d949116",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Sit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "5ddc8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(path, 'rb') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "gyro_df = data['gyro']\n",
    "accel_df = data['accel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "3e6157e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp = pl.DataFrame(accel_df)\n",
    "gyro_temp = pl.DataFrame(gyro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "8b3ea5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp = accel_temp.with_columns(pl.lit('A').alias('Usuario'))\n",
    "gyro_temp  = gyro_temp.with_columns(pl.lit('A').alias('Usuario'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "7fb43d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_temp   = accel_temp.with_columns(pl.lit(target).alias('gt'))\n",
    "gyro_temp    = gyro_temp.with_columns(pl.lit(target).alias('gt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "dce7a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = normalize_columns(accel_temp,\n",
    "                            user_col_name  = \"Usuario\", \n",
    "                            timestamp_col_name = \"timestamp\", \n",
    "                            label_col_name = \"gt\", \n",
    "                            x_col_name = \"x\", \n",
    "                            y_col_name = \"y\", \n",
    "                            z_col_name = \"z\")\n",
    "\n",
    "df_gyro = normalize_columns(gyro_temp, \n",
    "                            user_col_name  = \"Usuario\", \n",
    "                            timestamp_col_name = \"timestamp\", \n",
    "                            label_col_name = \"gt\", \n",
    "                            x_col_name = \"x\", \n",
    "                            y_col_name = \"y\", \n",
    "                            z_col_name = \"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "26a5ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel = convert_timestamp(df_accel)\n",
    "df_gyro = convert_timestamp(df_gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "1cf30484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_axes_by_activity(df_gyro, df_accel, max_samples_per_activity=1000, figsize=(15, 12)):\n",
    "    \"\"\"\n",
    "    Visualiza los ejes X, Y, Z del giroscopio y aceler√≥metro por cada actividad\n",
    "    \"\"\"\n",
    "    # Obtener actividades √∫nicas\n",
    "    activities = df_gyro['Activity Label'].unique().tolist()\n",
    "    n_activities = len(activities)\n",
    "    \n",
    "    # Crear subplots\n",
    "    fig, axes = plt.subplots(n_activities, 2, figsize=figsize)\n",
    "    if n_activities == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, activity in enumerate(activities):\n",
    "        # Filtrar datos por actividad\n",
    "        gyro_activity = df_gyro[df_gyro['Activity Label'] == activity]\n",
    "        accel_activity =  df_accel[df_accel['Activity Label'] == activity]\n",
    "        \n",
    "        # Limitar muestras para mejor visualizaci√≥n\n",
    "        if len(gyro_activity) > max_samples_per_activity:\n",
    "            gyro_activity = gyro_activity.head(max_samples_per_activity)\n",
    "        if len(accel_activity) > max_samples_per_activity:\n",
    "            accel_activity = accel_activity.head(max_samples_per_activity)\n",
    "        \n",
    "        # Convertir a pandas para plotting\n",
    "        gyro_pd = gyro_activity.copy()\n",
    "        accel_pd = accel_activity.copy()\n",
    "        \n",
    "        # Plot Giroscopio\n",
    "        axes[i, 0].plot(gyro_pd['X'], label='X', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].plot(gyro_pd['Y'], label='Y', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].plot(gyro_pd['Z'], label='Z', alpha=0.7, linewidth=1)\n",
    "        axes[i, 0].set_title(f'Giroscopio - {activity}')\n",
    "        axes[i, 0].set_ylabel('Valor')\n",
    "        axes[i, 0].legend()\n",
    "        axes[i, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot Aceler√≥metro\n",
    "        axes[i, 1].plot(accel_pd['X'], label='X', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].plot(accel_pd['Y'], label='Y', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].plot(accel_pd['Z'], label='Z', alpha=0.7, linewidth=1)\n",
    "        axes[i, 1].set_title(f'Aceler√≥metro - {activity}')\n",
    "        axes[i, 1].set_ylabel('Valor')\n",
    "        axes[i, 1].legend()\n",
    "        axes[i, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # A√±adir xlabel solo en la √∫ltima fila\n",
    "        if i == n_activities - 1:\n",
    "            axes[i, 0].set_xlabel('Muestra')\n",
    "            axes[i, 1].set_xlabel('Muestra')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar visualizaci√≥n\n",
    "# plot_axes_by_activity(df_gyro.to_pandas(), df_accel.to_pandas(), max_samples_per_activity = 2000,  figsize = (20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "532d17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sampling_rate(df, user_id=None, activity=None, plot=True):\n",
    "    \"\"\"\n",
    "    Analiza la frecuencia de muestreo real de los datos\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con datos de sensores\n",
    "        user_id: Usuario espec√≠fico (opcional)\n",
    "        activity: Actividad espec√≠fica (opcional)\n",
    "        plot: Si mostrar gr√°ficos\n",
    "    \n",
    "    Returns:\n",
    "        dict: Informaci√≥n detallada del muestreo\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Convertir a pandas si es necesario\n",
    "    if hasattr(df, 'to_pandas'):\n",
    "        df_pd = df.to_pandas()\n",
    "    else:\n",
    "        df_pd = df.copy()\n",
    "    \n",
    "    # Filtrar por usuario y/o actividad si se especifica\n",
    "    if user_id is not None:\n",
    "        df_pd = df_pd[df_pd['Subject-id'] == user_id]\n",
    "    if activity is not None:\n",
    "        df_pd = df_pd[df_pd['Activity Label'] == activity]\n",
    "    \n",
    "    # Asegurar que Timestamp es datetime\n",
    "    if df_pd['Timestamp'].dtype == 'object':\n",
    "        df_pd['Timestamp'] = pd.to_datetime(df_pd['Timestamp'])\n",
    "    elif df_pd['Timestamp'].dtype == 'int64':\n",
    "        df_pd['Timestamp'] = pd.to_datetime(df_pd['Timestamp'])\n",
    "    \n",
    "    print(f\"üìä AN√ÅLISIS DE FRECUENCIA DE MUESTREO\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"  Total de muestras: {len(df_pd):,}\")\n",
    "    \n",
    "    if len(df_pd) < 2:\n",
    "        print(\"‚ùå Insuficientes datos para an√°lisis\")\n",
    "        return None\n",
    "    \n",
    "    # Ordenar por timestamp\n",
    "    df_pd = df_pd.sort_values('Timestamp')\n",
    "    \n",
    "    # Calcular diferencias de tiempo\n",
    "    time_diffs = df_pd['Timestamp'].diff().dt.total_seconds().dropna()\n",
    "    \n",
    "    # Estad√≠sticas generales\n",
    "    total_duration = (df_pd['Timestamp'].max() - df_pd['Timestamp'].min()).total_seconds()\n",
    "    avg_sampling_rate = (len(df_pd) - 1) / total_duration if total_duration > 0 else 0\n",
    "    \n",
    "    print(f\"  Duraci√≥n total: {total_duration:.2f} segundos\")\n",
    "    print(f\"  üì° Frecuencia promedio: {avg_sampling_rate:.2f} Hz\")\n",
    "    \n",
    "    # Estad√≠sticas de intervalos\n",
    "    print(f\"\\nüìà ESTAD√çSTICAS DE INTERVALOS:\")\n",
    "    print(f\"  Intervalo promedio: {time_diffs.mean():.4f}s ({1/time_diffs.mean():.1f} Hz)\")\n",
    "    print(f\"  Intervalo m√≠nimo: {time_diffs.min():.4f}s ({1/time_diffs.min():.1f} Hz)\")\n",
    "    print(f\"  Intervalo m√°ximo: {time_diffs.max():.4f}s ({1/time_diffs.max():.1f} Hz)\")\n",
    "    print(f\"  Desviaci√≥n est√°ndar: {time_diffs.std():.4f}s\")\n",
    "    \n",
    "    # Detectar frecuencias instant√°neas\n",
    "    instant_frequencies = 1 / time_diffs\n",
    "    instant_frequencies = instant_frequencies[instant_frequencies < 1000]  # Filtrar valores extremos\n",
    "    \n",
    "    print(f\"\\nüéØ FRECUENCIAS INSTANT√ÅNEAS:\")\n",
    "    print(f\"  Frecuencia modal: {instant_frequencies.mode().iloc[0]:.1f} Hz\")\n",
    "    print(f\"  Mediana: {instant_frequencies.median():.1f} Hz\")\n",
    "    print(f\"  Rango: {instant_frequencies.min():.1f} - {instant_frequencies.max():.1f} Hz\")\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('An√°lisis de Frecuencia de Muestreo', fontsize=16)\n",
    "        \n",
    "        # 1. Histograma de intervalos\n",
    "        axes[0,0].hist(time_diffs, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0,0].set_title('Distribuci√≥n de Intervalos de Tiempo')\n",
    "        axes[0,0].set_xlabel('Intervalo (segundos)')\n",
    "        axes[0,0].set_ylabel('Frecuencia')\n",
    "        axes[0,0].axvline(time_diffs.mean(), color='red', linestyle='--', \n",
    "                         label=f'Media: {time_diffs.mean():.4f}s')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Histograma de frecuencias instant√°neas\n",
    "        axes[0,1].hist(instant_frequencies, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[0,1].set_title('Distribuci√≥n de Frecuencias Instant√°neas')\n",
    "        axes[0,1].set_xlabel('Frecuencia (Hz)')\n",
    "        axes[0,1].set_ylabel('Frecuencia')\n",
    "        axes[0,1].axvline(instant_frequencies.median(), color='red', linestyle='--', \n",
    "                         label=f'Mediana: {instant_frequencies.median():.1f}Hz')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Serie temporal de intervalos\n",
    "        sample_indices = np.linspace(0, len(time_diffs)-1, min(1000, len(time_diffs))).astype(int)\n",
    "        axes[1,0].plot(sample_indices, time_diffs.iloc[sample_indices], 'b-', alpha=0.7, linewidth=1)\n",
    "        axes[1,0].set_title('Serie Temporal de Intervalos')\n",
    "        axes[1,0].set_xlabel('Muestra')\n",
    "        axes[1,0].set_ylabel('Intervalo (segundos)')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Serie temporal de frecuencias\n",
    "        axes[1,1].plot(sample_indices, instant_frequencies.iloc[sample_indices], 'g-', alpha=0.7, linewidth=1)\n",
    "        axes[1,1].set_title('Serie Temporal de Frecuencias')\n",
    "        axes[1,1].set_xlabel('Muestra')\n",
    "        axes[1,1].set_ylabel('Frecuencia (Hz)')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Detectar irregularidades\n",
    "    print(f\"\\nüîç DETECCI√ìN DE IRREGULARIDADES:\")\n",
    "    \n",
    "    # Gaps grandes (> 1 segundo)\n",
    "    large_gaps = time_diffs[time_diffs > 1.0]\n",
    "    print(f\"  Gaps > 1s: {len(large_gaps)} ({100*len(large_gaps)/len(time_diffs):.1f}%)\")\n",
    "    \n",
    "    # Variabilidad alta\n",
    "    cv = time_diffs.std() / time_diffs.mean()  # Coeficiente de variaci√≥n\n",
    "    print(f\"  Coeficiente de variaci√≥n: {cv:.3f}\")\n",
    "    \n",
    "    if cv > 0.1:\n",
    "        print(\"  ‚ö†Ô∏è Alta variabilidad en el muestreo\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ Muestreo relativamente estable\")\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df_pd),\n",
    "        'duration_seconds': total_duration,\n",
    "        'avg_sampling_rate': avg_sampling_rate,\n",
    "        'time_intervals': {\n",
    "            'mean': time_diffs.mean(),\n",
    "            'std': time_diffs.std(),\n",
    "            'min': time_diffs.min(),\n",
    "            'max': time_diffs.max()\n",
    "        },\n",
    "        'frequencies': {\n",
    "            'mean': instant_frequencies.mean(),\n",
    "            'median': instant_frequencies.median(),\n",
    "            'mode': instant_frequencies.mode().iloc[0] if len(instant_frequencies.mode()) > 0 else None,\n",
    "            'min': instant_frequencies.min(),\n",
    "            'max': instant_frequencies.max()\n",
    "        },\n",
    "        'irregularities': {\n",
    "            'large_gaps_count': len(large_gaps),\n",
    "            'coefficient_of_variation': cv\n",
    "        }\n",
    "    }\n",
    "\n",
    "# # Analizar tus datos\n",
    "# print(\"üîç Analizando frecuencia de muestreo de df_accel...\")\n",
    "# sampling_info = analyze_sampling_rate(df_accel, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "34865d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_windows_250_timesteps_robust(df, window_seconds=5, overlap_percent=50, \n",
    "                                           sampling_rate=20, target_timesteps=250,\n",
    "                                           min_data_threshold=0.5, max_gap_seconds=1.0):\n",
    "    \"\"\"\n",
    "    Versi√≥n ROBUSTA: Crea ventanas basadas en TIEMPO REAL con validaci√≥n mejorada\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con datos de sensores (Polars o Pandas)\n",
    "        window_seconds: Duraci√≥n de la ventana en segundos (default: 5)\n",
    "        overlap_percent: Porcentaje de solapamiento (default: 50)\n",
    "        sampling_rate: Frecuencia de muestreo en Hz (default: 20)\n",
    "        target_timesteps: N√∫mero objetivo de timesteps por ventana (default: 250)\n",
    "        min_data_threshold: Umbral m√≠nimo de datos v√°lidos (0.5 = 50%)\n",
    "        max_gap_seconds: M√°ximo gap permitido en segundos (1.0s)\n",
    "        \n",
    "    Returns:\n",
    "        X: Array con forma (n_windows, 250, 3) - datos de ventanas\n",
    "        y: Array con etiquetas de actividad\n",
    "        subjects: Array con IDs de usuario\n",
    "        metadata: DataFrame con informaci√≥n de las ventanas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üîß Configuraci√≥n de ventanas RAW ROBUSTA:\")\n",
    "    print(f\"  Duraci√≥n: {window_seconds}s\")\n",
    "    print(f\"  Timesteps objetivo: {target_timesteps}\")\n",
    "    print(f\"  Frecuencia de muestreo: {sampling_rate}Hz\")\n",
    "    print(f\"  Solapamiento: {overlap_percent}%\")\n",
    "    print(f\"  Umbral m√≠nimo de datos: {min_data_threshold*100:.1f}%\")\n",
    "    print(f\"  M√°ximo gap permitido: {max_gap_seconds}s\")\n",
    "    \n",
    "    # Convertir a pandas si es necesario\n",
    "    if hasattr(df, 'to_pandas'):\n",
    "        df_pd = df.to_pandas()\n",
    "    else:\n",
    "        df_pd = df.copy()\n",
    "    \n",
    "    # Asegurar que Timestamp es datetime\n",
    "    if df_pd['Timestamp'].dtype == 'object':\n",
    "        df_pd['Timestamp'] = pd.to_datetime(df_pd['Timestamp'])\n",
    "    elif df_pd['Timestamp'].dtype == 'int64':\n",
    "        df_pd['Timestamp'] = pd.to_datetime(df_pd['Timestamp'])\n",
    "    \n",
    "    # Calcular par√°metros de tiempo\n",
    "    window_duration_ns = int(window_seconds * 1e9)\n",
    "    step_duration_ns = int(window_duration_ns * (100 - overlap_percent) / 100)\n",
    "    \n",
    "    print(f\"  Duraci√≥n de ventana: {window_seconds}s\")\n",
    "    print(f\"  Paso entre ventanas: {step_duration_ns / 1e9:.2f}s\")\n",
    "    \n",
    "    # Listas para almacenar resultados\n",
    "    X_windows = []\n",
    "    y_labels = []\n",
    "    subjects_list = []\n",
    "    metadata_list = []\n",
    "    \n",
    "    total_windows_attempted = 0\n",
    "    total_windows_created = 0\n",
    "    \n",
    "    # Procesar por usuario y actividad\n",
    "    for (user_id, activity), group in df_pd.groupby(['Subject-id', 'Activity Label']):\n",
    "        \n",
    "        # Ordenar por timestamp y limpiar datos\n",
    "        group = group.sort_values('Timestamp').reset_index(drop=True)\n",
    "        group = group.dropna(subset=['X', 'Y', 'Z', 'Timestamp'])\n",
    "        \n",
    "        if len(group) < window_seconds * sampling_rate:\n",
    "            print(f\"‚ö†Ô∏è Usuario {user_id}, Actividad {activity}: Muy pocos datos ({len(group)} muestras)\")\n",
    "            continue\n",
    "        \n",
    "        # Convertir timestamps a nanosegundos\n",
    "        if group['Timestamp'].dtype.name.startswith('datetime'):\n",
    "            timestamps_ns = group['Timestamp'].astype('int64')\n",
    "        else:\n",
    "            timestamps_ns = group['Timestamp'].values\n",
    "        \n",
    "        print(f\"üë§ Usuario {user_id}, Actividad {activity}: {len(group)} muestras\")\n",
    "        \n",
    "        # Obtener rango temporal\n",
    "        start_time_ns = timestamps_ns.min()\n",
    "        end_time_ns = timestamps_ns.max()\n",
    "        total_duration_s = (end_time_ns - start_time_ns) / 1e9\n",
    "        \n",
    "        print(f\"   Duraci√≥n total: {total_duration_s:.1f}s\")\n",
    "        \n",
    "        # Detectar y reportar gaps grandes\n",
    "        time_diffs = np.diff(timestamps_ns) / 1e9  # Convertir a segundos\n",
    "        large_gaps = time_diffs > max_gap_seconds\n",
    "        if np.any(large_gaps):\n",
    "            n_gaps = np.sum(large_gaps)\n",
    "            max_gap = np.max(time_diffs)\n",
    "            print(f\"   ‚ö†Ô∏è Detectados {n_gaps} gaps > {max_gap_seconds}s (m√°ximo: {max_gap:.1f}s)\")\n",
    "        \n",
    "        # Crear ventanas deslizantes\n",
    "        window_count = 0\n",
    "        current_start_ns = start_time_ns\n",
    "        \n",
    "        while current_start_ns + window_duration_ns <= end_time_ns:\n",
    "            total_windows_attempted += 1\n",
    "            current_end_ns = current_start_ns + window_duration_ns\n",
    "            \n",
    "            # Filtrar datos en esta ventana temporal\n",
    "            window_mask = (\n",
    "                (timestamps_ns >= current_start_ns) & \n",
    "                (timestamps_ns < current_end_ns)\n",
    "            )\n",
    "            window_data_df = group[window_mask]\n",
    "            \n",
    "            # Validaci√≥n de ventana\n",
    "            is_valid, validation_info = validate_window_data(\n",
    "                window_data_df, \n",
    "                window_seconds, \n",
    "                sampling_rate, \n",
    "                min_data_threshold,\n",
    "                max_gap_seconds\n",
    "            )\n",
    "            \n",
    "            if is_valid:\n",
    "                # Extraer datos de sensores\n",
    "                sensor_data = window_data_df[['X', 'Y', 'Z']].values\n",
    "                window_timestamps = window_data_df['Timestamp'].values\n",
    "                \n",
    "                try:\n",
    "                    # Redimensionar/interpolar a target_timesteps\n",
    "                    resampled_window = resample_window_robust(\n",
    "                        sensor_data, window_timestamps, target_timesteps, window_seconds\n",
    "                    )\n",
    "                    \n",
    "                    # Verificar calidad final\n",
    "                    if is_window_quality_good(resampled_window):\n",
    "                        # Guardar datos\n",
    "                        X_windows.append(resampled_window)\n",
    "                        y_labels.append(activity)\n",
    "                        subjects_list.append(user_id)\n",
    "                        \n",
    "                        # Metadata extendida\n",
    "                        metadata_list.append({\n",
    "                            'Subject-id': user_id,\n",
    "                            'Activity Label': activity,\n",
    "                            'window_start': pd.to_datetime(current_start_ns),\n",
    "                            'window_end': pd.to_datetime(current_end_ns),\n",
    "                            'original_samples': len(window_data_df),\n",
    "                            'resampled_timesteps': target_timesteps,\n",
    "                            'window_idx': window_count,\n",
    "                            'actual_duration_s': window_seconds,\n",
    "                            'data_coverage': validation_info['data_coverage'],\n",
    "                            'max_gap_s': validation_info['max_gap'],\n",
    "                            'sampling_rate_actual': validation_info['actual_rate']\n",
    "                        })\n",
    "                        \n",
    "                        window_count += 1\n",
    "                        total_windows_created += 1\n",
    "                    else:\n",
    "                        print(f\"   ‚ùå Ventana {window_count}: Calidad de datos insuficiente despu√©s de interpolaci√≥n\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Ventana {window_count}: Error en interpolaci√≥n - {str(e)}\")\n",
    "            \n",
    "            else:\n",
    "                # No mostrar warning para cada ventana inv√°lida, solo resumen\n",
    "                pass\n",
    "            \n",
    "            # Mover al siguiente inicio de ventana\n",
    "            current_start_ns += step_duration_ns\n",
    "        \n",
    "        print(f\"  ‚úÖ Creadas {window_count} ventanas v√°lidas\")\n",
    "    \n",
    "    # Resumen final\n",
    "    print(f\"\\nüìä RESUMEN DE VALIDACI√ìN:\")\n",
    "    print(f\"  Ventanas intentadas: {total_windows_attempted}\")\n",
    "    print(f\"  Ventanas creadas: {total_windows_created}\")\n",
    "    print(f\"  Tasa de √©xito: {(total_windows_created/total_windows_attempted)*100:.1f}%\")\n",
    "    \n",
    "    # Convertir a arrays numpy\n",
    "    if len(X_windows) > 0:\n",
    "        X = np.array(X_windows)\n",
    "        y = np.array(y_labels)\n",
    "        subjects = np.array(subjects_list)\n",
    "        metadata_df = pd.DataFrame(metadata_list)\n",
    "        \n",
    "        print(f\"\\nüìä RESULTADO FINAL (ROBUSTO):\")\n",
    "        print(f\"  Forma de X: {X.shape}\")\n",
    "        print(f\"  Forma de y: {y.shape}\")\n",
    "        print(f\"  Total ventanas: {len(X)}\")\n",
    "        print(f\"  Usuarios √∫nicos: {len(np.unique(subjects))}\")\n",
    "        print(f\"  Actividades √∫nicas: {sorted(np.unique(y))}\")\n",
    "        \n",
    "        return X, y, subjects, metadata_df\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No se crearon ventanas v√°lidas\")\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "def validate_window_data(window_data_df, window_seconds, sampling_rate, \n",
    "                        min_data_threshold, max_gap_seconds):\n",
    "    \"\"\"\n",
    "    Valida si una ventana de datos es aceptable\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si la ventana es v√°lida\n",
    "        dict: Informaci√≥n de validaci√≥n\n",
    "    \"\"\"\n",
    "    if len(window_data_df) == 0:\n",
    "        return False, {'reason': 'empty', 'data_coverage': 0, 'max_gap': float('inf'), 'actual_rate': 0}\n",
    "    \n",
    "    # Calcular cobertura de datos esperada\n",
    "    expected_samples = window_seconds * sampling_rate\n",
    "    actual_samples = len(window_data_df)\n",
    "    data_coverage = actual_samples / expected_samples\n",
    "    \n",
    "    # Si hay muy pocos datos\n",
    "    if data_coverage < min_data_threshold:\n",
    "        return False, {\n",
    "            'reason': 'insufficient_data', \n",
    "            'data_coverage': data_coverage,\n",
    "            'max_gap': float('inf'),\n",
    "            'actual_rate': 0\n",
    "        }\n",
    "    \n",
    "    # Calcular gaps en los datos\n",
    "    if len(window_data_df) > 1:\n",
    "        timestamps = pd.to_datetime(window_data_df['Timestamp'])\n",
    "        time_diffs = timestamps.diff().dt.total_seconds().fillna(0)\n",
    "        max_gap = time_diffs.max()\n",
    "        actual_rate = len(window_data_df) / (timestamps.max() - timestamps.min()).total_seconds()\n",
    "    else:\n",
    "        max_gap = 0\n",
    "        actual_rate = sampling_rate\n",
    "    \n",
    "    # Si hay gaps muy grandes\n",
    "    if max_gap > max_gap_seconds:\n",
    "        return False, {\n",
    "            'reason': 'large_gap', \n",
    "            'data_coverage': data_coverage,\n",
    "            'max_gap': max_gap,\n",
    "            'actual_rate': actual_rate\n",
    "        }\n",
    "    \n",
    "    # Verificar que no hay valores NaN o infinitos en los sensores\n",
    "    sensor_data = window_data_df[['X', 'Y', 'Z']].values\n",
    "    if np.any(np.isnan(sensor_data)) or np.any(np.isinf(sensor_data)):\n",
    "        return False, {\n",
    "            'reason': 'invalid_values',\n",
    "            'data_coverage': data_coverage,\n",
    "            'max_gap': max_gap,\n",
    "            'actual_rate': actual_rate\n",
    "        }\n",
    "    \n",
    "    return True, {\n",
    "        'reason': 'valid',\n",
    "        'data_coverage': data_coverage,\n",
    "        'max_gap': max_gap,\n",
    "        'actual_rate': actual_rate\n",
    "    }\n",
    "\n",
    "\n",
    "def resample_window_robust(sensor_data, timestamps, target_timesteps, window_seconds):\n",
    "    \"\"\"\n",
    "    Versi√≥n robusta de remuestreo con m√∫ltiples estrategias\n",
    "    \"\"\"\n",
    "    from scipy.interpolate import interp1d\n",
    "    from scipy import signal\n",
    "    \n",
    "    if len(sensor_data) == 0:\n",
    "        return np.zeros((target_timesteps, 3))\n",
    "    \n",
    "    original_timesteps = len(sensor_data)\n",
    "    \n",
    "    if original_timesteps == target_timesteps:\n",
    "        return sensor_data.copy()\n",
    "    \n",
    "    if original_timesteps == 1:\n",
    "        return np.tile(sensor_data[0], (target_timesteps, 1))\n",
    "    \n",
    "    try:\n",
    "        # Estrategia 1: Interpolaci√≥n temporal precisa\n",
    "        if hasattr(timestamps[0], 'timestamp'):\n",
    "            time_seconds = np.array([t.timestamp() for t in timestamps])\n",
    "        elif isinstance(timestamps[0], pd.Timestamp):\n",
    "            time_seconds = np.array([t.timestamp() for t in timestamps])\n",
    "        else:\n",
    "            time_seconds = timestamps.astype('int64') / 1e9\n",
    "        \n",
    "        # Normalizar tiempos\n",
    "        time_min = time_seconds.min()\n",
    "        time_max = time_seconds.max()\n",
    "        \n",
    "        if time_max > time_min:\n",
    "            relative_times = (time_seconds - time_min) / (time_max - time_min)\n",
    "        else:\n",
    "            relative_times = np.linspace(0, 1, len(time_seconds))\n",
    "        \n",
    "        # Crear tiempos objetivo uniformes\n",
    "        target_times = np.linspace(0, 1, target_timesteps)\n",
    "        \n",
    "        # Interpolar cada eje\n",
    "        resampled_data = np.zeros((target_timesteps, 3))\n",
    "        \n",
    "        for axis in range(3):\n",
    "            try:\n",
    "                # Estrategia de interpolaci√≥n seg√∫n la cantidad de datos\n",
    "                if original_timesteps >= target_timesteps:\n",
    "                    # Downsample: usar signal.resample para preservar caracter√≠sticas\n",
    "                    resampled_axis = signal.resample(sensor_data[:, axis], target_timesteps)\n",
    "                else:\n",
    "                    # Upsample: usar interpolaci√≥n\n",
    "                    if len(np.unique(relative_times)) > 1:\n",
    "                        interpolator = interp1d(\n",
    "                            relative_times, \n",
    "                            sensor_data[:, axis],\n",
    "                            kind='cubic' if original_timesteps >= 4 else 'linear',\n",
    "                            bounds_error=False,\n",
    "                            fill_value='extrapolate'\n",
    "                        )\n",
    "                        resampled_axis = interpolator(target_times)\n",
    "                    else:\n",
    "                        resampled_axis = np.full(target_timesteps, sensor_data[0, axis])\n",
    "                \n",
    "                resampled_data[:, axis] = resampled_axis\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Fallback: interpolaci√≥n lineal simple\n",
    "                resampled_data[:, axis] = np.interp(\n",
    "                    target_times, relative_times, sensor_data[:, axis]\n",
    "                )\n",
    "        \n",
    "        return resampled_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en remuestreo robusto: {str(e)}\")\n",
    "        # √öltimo fallback: replicar la primera muestra\n",
    "        return np.tile(sensor_data[0], (target_timesteps, 1))\n",
    "\n",
    "\n",
    "def is_window_quality_good(resampled_window, max_std_threshold=50.0):\n",
    "    \"\"\"\n",
    "    Verifica la calidad final de una ventana remuestreada\n",
    "    \"\"\"\n",
    "    # Verificar NaN o infinitos\n",
    "    if np.any(np.isnan(resampled_window)) or np.any(np.isinf(resampled_window)):\n",
    "        return False\n",
    "    \n",
    "    # Verificar valores extremos (posibles errores de interpolaci√≥n)\n",
    "    if np.any(np.abs(resampled_window) > 1000):  # Ajustar seg√∫n tus datos\n",
    "        return False\n",
    "    \n",
    "    # Verificar varianza (datos demasiado planos pueden indicar error)\n",
    "    for axis in range(resampled_window.shape[1]):\n",
    "        std_axis = np.std(resampled_window[:, axis])\n",
    "        if std_axis > max_std_threshold:  # Varianza excesiva\n",
    "            return False\n",
    "        if std_axis < 0.001:  # Datos demasiado planos\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "97c88ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuraci√≥n de ventanas RAW ROBUSTA:\n",
      "  Duraci√≥n: 5s\n",
      "  Timesteps objetivo: 100\n",
      "  Frecuencia de muestreo: 20Hz\n",
      "  Solapamiento: 50%\n",
      "  Umbral m√≠nimo de datos: 80.0%\n",
      "  M√°ximo gap permitido: 1.0s\n",
      "  Duraci√≥n de ventana: 5s\n",
      "  Paso entre ventanas: 2.50s\n",
      "üë§ Usuario A, Actividad Sit: 1459 muestras\n",
      "   Duraci√≥n total: 58.0s\n",
      "  ‚úÖ Creadas 22 ventanas v√°lidas\n",
      "\n",
      "üìä RESUMEN DE VALIDACI√ìN:\n",
      "  Ventanas intentadas: 22\n",
      "  Ventanas creadas: 22\n",
      "  Tasa de √©xito: 100.0%\n",
      "\n",
      "üìä RESULTADO FINAL (ROBUSTO):\n",
      "  Forma de X: (22, 100, 3)\n",
      "  Forma de y: (22,)\n",
      "  Total ventanas: 22\n",
      "  Usuarios √∫nicos: 1\n",
      "  Actividades √∫nicas: ['Sit']\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all, subjects_all, metadata_all = create_raw_windows_250_timesteps_robust(\n",
    "    df=df_accel,\n",
    "    window_seconds=5,\n",
    "    overlap_percent=50,\n",
    "    sampling_rate=20,\n",
    "    target_timesteps=100,\n",
    "    min_data_threshold=0.8,  # 80% m√≠nimo de datos\n",
    "    max_gap_seconds=1.0      # M√°ximo 1 segundo de gap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "c071f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "# Cargar como funci√≥n concreta\n",
    "loaded = tf.saved_model.load(r\"F:\\UPC\\Tesis\\HARbit-Model\\src\\cnn_temporal_20_epochs_93\\saved_model\")\n",
    "infer = loaded.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "e0328313",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.constant(X_all, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "5968a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = joblib.load(r'F:\\UPC\\Tesis\\HARbit-Model\\src\\cnn_temporal_20_epochs_93\\label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "5fd61316",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = infer(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "a8b861c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = label_encoder.transform(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "308c6c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "[[22]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Ejemplo: y_pred con probabilidades\n",
    "y_pred_probs = list(y_pred.values())[0].numpy()\n",
    "\n",
    "# Convertir a clases predichas (√≠ndice del m√°ximo)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Comparar con y_real (aseg√∫rate de que y_real tenga etiquetas 0..N-1)\n",
    "acc = accuracy_score(y_all, y_pred_classes)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# Reporte m√°s detallado\n",
    "print(classification_report(y_all, y_pred_classes))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "print(confusion_matrix(y_all, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "dcbf119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "ba1790ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Eat', 'Others', 'Sit', 'Stand', 'Type', 'Walk', 'Workouts',\n",
       "       'Write'], dtype='<U8')"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "9e6e6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
